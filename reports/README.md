# MFCS Benchmark Reports

This directory contains benchmark reports and analysis results for the MFCS (Model Function Calling System) benchmark suite.

## Contents

The reports include:
- Summary reports (`summary_*.md`) - Overall benchmark results including:
  - Model accuracy
  - Response time
  - Test case success rate
  - Tool usage statistics
  - Test status
- Detailed reports (`report_*.md`) - In-depth analysis for each test case including:
  - Test environment details
  - Input/output comparison
  - Tool usage analysis
  - Semantic matching results
  - Token usage statistics

## Organization

Reports are organized by timestamp (YYYYMMDD_HHMMSS format) and include both summary and detailed reports for each benchmark run.

Reports are automatically generated when running benchmarks using the `run_benchmark.py` script. 